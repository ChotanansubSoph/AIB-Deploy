from cgi import test
import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
import time

import tensorflow as tf 
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import transformers


from io import StringIO

from assets.module import LSTM_PP
from assets.module import WangChan_PP

#Load Model and Tokenizer 
@st.cache(allow_output_mutation=True,show_spinner=False,ttl=1800)
def load_model_lstm(): return LSTM_PP.load_LSTM()

@st.cache(allow_output_mutation=True,show_spinner=False,ttl=1800)
def load_model_wangchan(): return WangChan_PP.load_wangchan()

@st.cache(hash_funcs={transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast: hash},
                    allow_output_mutation=True,
                    show_spinner=False,
                    ttl=1800)
def load_wangchan_tokenizer(): return WangChan_PP.load_wangchan_tokenizer()

#Set up 

placeholder = "‡∏Å‡∏£‡∏∞‡∏´‡∏±‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏µ‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‡∏Å‡∏£‡∏∞‡∏´‡∏≤‡∏á ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏µ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏µ‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢ ‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ú‡∏µ‡∏Å‡∏£‡∏∞‡∏™‡∏∑‡∏≠ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏µ‡∏Å‡∏£‡∏∞‡∏´‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏™‡∏¢‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏Ñ‡∏°‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Å‡∏•‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÑ‡∏î‡πâ‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏ï‡∏±‡∏ß"

AIBlogo_image = Image.open('assets/img/AIBlogo.png')
book_image = Image.open('assets/img/book.jpg')

DOMAIN_LIST = ['‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πåüî¨',
               '‡∏®‡∏¥‡∏•‡∏õ‡∏Å‡∏£‡∏£‡∏°üñåÔ∏è',
               '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠üôèüèº',
               '‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå üíµ',
               '‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πåüîé',
               '‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£üîÆ',
               '‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞ ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ö‡∏£‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡πåüå±',
               '‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤üìö', ]

with st.sidebar:
    st.image(AIBlogo_image,width=100)

    st.header("üñ•Ô∏è‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ")
    st.write("‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ [AI Builder 2022](https://ai-builders.github.io/) ‡πÇ‡∏î‡∏¢‡πÑ‡∏î‡πâ‡∏à‡∏±‡∏Å‡∏ó‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ß‡∏î‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏ß‡∏î‡∏ß‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡∏ô‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á [WangChanBERTa](https://airesearch.in.th/releases/wangchanberta-pre-trained-thai-language-model/) ‡πÅ‡∏•‡∏∞ LSTM ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å [Thai National Corpus](https://www.arts.chula.ac.th/ling/tnc/) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 49,153 ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ",unsafe_allow_html=True)
    
    st.header("üåê‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
    st.write("‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏à‡∏≤‡∏Å TNC : THAI NATIONAL CORPUS (Third Edition) ‡πÉ‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏π‡∏õ‡∏ñ‡∏±‡∏°‡∏†‡πå‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡πÄ‡∏ó‡∏û‡∏£‡∏±‡∏ï‡∏ô‡∏£‡∏≤‡∏ä‡∏™‡∏∏‡∏î‡∏≤‡∏Ø ‡∏™‡∏¢‡∏≤‡∏°‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏Å‡∏∏‡∏°‡∏≤‡∏£‡∏µ ‡∏†‡∏≤‡∏Ñ‡∏ß‡∏¥‡∏ä‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢ [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°](https://www.arts.chula.ac.th/ling/tnc/)")



st.header('‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏ß‡∏î‡∏ß‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢üìîüîç')


with open("assets/webfonts/font.txt") as f:
    st.markdown(f.read(),unsafe_allow_html=True)
with open("assets/css/style.css") as f:
    st.markdown(f"<style> {f.read()} </style>",unsafe_allow_html=True)
hide_table_index = """
            <style>         
            thead {display:none}  
            tbody th {display:none}
            .blank {display:none}
            </style>
            """ 
st.markdown(hide_table_index, unsafe_allow_html=True)





st.image(book_image)
#<a href='https://www.freepik.com/photos/library-books'>Library books photo created by jcomp - www.freepik.com</a>




left_col, right_col = st.columns(2)

with left_col:
    isDataComplete = False
    #Input Method Selection
    st.subheader("1. ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‚öôÔ∏è")
    input_option = st.selectbox(
                    "üî∏ 1.1 ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°üìù",
                    ("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‚å®Ô∏è","‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πåüì§ "))

    st.info(f'üîπ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å {input_option}')

    if input_option == "‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‚å®Ô∏è":
        input_text = st.text_area("üî∏ 1.2 ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‚å®Ô∏è",
                placeholder,
                max_chars=5000)

    else:
        input_text = None
        uploaded_file = st.file_uploader("üî∏ 1.2 ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• txt.)")
        if uploaded_file != None:
            if uploaded_file.type == "text/plain":
                #st.write("yeh it's text file!")

                stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
                input_text = stringio.read()

            # elif uploaded_file.type == "text/csv":
            #     st.write("boom it's csv!") 
                

    #Model Selection     
    model_option = st.selectbox(
                    "üî∏ 1.3 ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á(Model)ü§ñ",
                    ("WangChanBERTa (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥üî•)","Long short-term memory (LSTM)"))
    if model_option == "WangChanBERTa (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥üî•)":
        selected_model = "WangChanBERTa"
    else:
        selected_model = "Long short-term memory (LSTM)"
    st.info(f'üîπ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á: {selected_model}')

    #Accept Button
    button = st.button('‡∏ï‡∏Å‡∏•‡∏á')
    if button:
        if input_text == None:
            alert_left = "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‚ö†Ô∏è"
        elif input_text == "":
            alert_left = "‡∏Å‡∏£‡∏ì‡∏∏‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‚ö†Ô∏è"
        else:
            alert_left = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‚úÖ"
            isDataComplete = True
        if isDataComplete != True:
            st.warning(alert_left)
        st.info(f"üîπ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: {alert_left}",)

        placeholder = input_text


with right_col: 
    st.subheader("2. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• üë©üèª‚Äçüíª")
    if button and isDataComplete:
        

        started_load_time = time.time()
        
        with st.spinner(text='‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‚åõÔ∏è (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô30‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)'):
            progress_bar = st.progress(0)
            lstm_model = load_model_lstm()
            progress_bar.progress(30)
            wangchan_model = load_model_wangchan()
            progress_bar.progress(60)
            wangchan_tokenizer = load_wangchan_tokenizer()
            progress_bar.progress(100)

        finished_load_time = time.time()
        loadModelTime = finished_load_time - started_load_time
        st.info("‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‚úÖ (‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ {:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)".format(loadModelTime))


        with st.spinner(text='‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‚åõÔ∏è'):
            

            started_time = time.time()
            if selected_model == "Long short-term memory (LSTM)":
                domainIndex, domainProb = LSTM_PP.all_preprocessing(input_text[:1500],lstm_model)
                predicted_domain = DOMAIN_LIST[domainIndex]
            else:
                domainIndex, domainProb = WangChan_PP.all_preprocessing(input_text[:1500],wangchan_model,wangchan_tokenizer)
                predicted_domain = DOMAIN_LIST[domainIndex]

            finished_time = time.time()
            processingTime = finished_time - started_time

            st.info("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‚úÖ (‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ {:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)".format(processingTime))
            lst = [['‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á(Model)ü§ñ',selected_model],
                   ['‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‚åõÔ∏è', "{:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ".format(processingTime)],
                   ['‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°üìÉ',input_text],
                   ['‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ß‡∏î‡∏ß‡∏áüìå', predicted_domain],
                   ['‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏áüìä', "{:.2f}%".format(domainProb*100)]
                  ]
            vizDF = pd.DataFrame(lst)
            st.table(vizDF)
            st.balloons()
            placeholder = input_text
            
    else:
        st.write("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•üí°")